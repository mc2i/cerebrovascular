{"cells":[{"cell_type":"markdown","metadata":{"id":"OMqD5rHkLaeT"},"source":["What datasets are supported?\n","\n","IXI and CASILab\n","\n","How hard would it be to include a new dataset?\n","\n","~2 days if like IXI or CASILab\n","\n","What files are excluded from each dataset?\n","\n","\n","\n","What preprocessing is ran?\n","\n","How are the labels received?\n","\n","What do I need to do to make it so that dementia score can be used instead? -> Nothing"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":659},"executionInfo":{"elapsed":37061,"status":"error","timestamp":1621383049415,"user":{"displayName":"Morgan Ciliv","photoUrl":"","userId":"00224338928243146060"},"user_tz":420},"id":"6I6SXElp8VoH","outputId":"3839763e-fe7a-45a2-f5cd-aed9e49e421e"},"outputs":[],"source":["#@title Installations, downloads, imports, settings\n","!pip install --upgrade --quiet ipdb\n","!pip install --upgrade --quiet nibabel #==3.1.0\n","!pip install --upgrade --quiet nilearn #==0.5.2\n","!pip install --upgrade â€“-quiet SimpleITK\n","!pip install --upgrade --quiet substring\n","!pip install --upgrade --quiet deprecated\n","!pip install --upgrade --quiet torchio\n","!curl -s -o colormap.txt https://raw.githubusercontent.com/thenineteen/Semiology-Visualisation-Tool/master/slicer/Resources/Color/BrainAnatomyLabelsV3_0.txt\n","!pip install --quiet cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl\n","# %xmode Verbose\n","import abc\n","import ipdb\n","import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","import nibabel as nib\n","# from nibabel.affines import rescale_affine\n","# if not os.path.exists('/usr/local/lib/python3.6/dist-packages/nibabel_320'):\n","#   !pip install 'nibabel>=3.2.0'\n","# import nibabel_320 as nib\n","import nilearn\n","from nilearn import plotting\n","try:\n","  import niwidgets\n","except:\n","  print(\"Not importing niwidgets since not installed\")\n","import SimpleITK as sitk\n","import tempfile\n","import unittest\n","import time\n","import datetime\n","import substring\n","import shlex\n","import pathlib\n","from pathlib import Path\n","import enum\n","from deprecated import deprecated\n","from google.colab import auth, drive\n","from tqdm.notebook import tqdm\n","import multiprocessing\n","import torch\n","from torch import nn\n","import torch_xla\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","import torch_xla.distributed.parallel_loader as pl\n","import torch_xla.debug.metrics as met\n","import torchio as tio\n","from torchio import DATA\n","from torchio.transforms import (\n","  RandomFlip,\n","  RandomAffine,\n","  RandomElasticDeformation,\n","  RandomNoise,\n","  RandomMotion,\n","  RandomBiasField,\n","  RescaleIntensity,\n","  Resample,\n","  ToCanonical,\n","  ZNormalization,\n","  CropOrPad,\n","  HistogramStandardization,\n","  OneOf,\n","  Compose,\n",")\n","import tensorflow as tf\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","print(tf.__version__)\n","from tensorflow import keras\n","from tensorflow.keras import Sequential, Model\n","from tensorflow.keras.layers import Input, Conv3D, Dropout, Activation, MaxPooling3D, Flatten, Dense\n","from tensorflow.keras.layers.experimental.preprocessing import Normalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import load_model\n","%load_ext tensorboard\n","import matplotlib.pyplot as plt\n","import seaborn as sns; sns.set()\n","import warnings\n","sns.set_style(\"whitegrid\", {'axes.grid' : False})\n","%config InlineBackend.figure_format = 'retina'\n","np.random.seed(0)"]},{"cell_type":"markdown","metadata":{"id":"1MUjP4jpC3ud"},"source":["Where to retrieve data\n","\n","What datasets\n","\n","Which files/Which model\n","\n","What *hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgZ4Ox4O6aG8"},"outputs":[],"source":["datasets_to_run_with = {'IXI', 'CASILab'}"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"p63_GD569uCg"},"outputs":[],"source":["move_tfrecords_to_cloud = False #@param {type: \"boolean\"}\n","use_cloud_tfrecords = False #@param {type: \"boolean\"}\n","# TODO: Have to use gcsfuse?\n","use_gcsfuse_tfrecords = False #@param {type: \"boolean\"}\n","use_google_drive_stored_tfrecords = not use_cloud_tfrecords and not use_gcsfuse_tfrecords\n","run_model = True #@param {type: \"boolean\"}\n","make_estimator = True # Delete? Must be true for now # is this true???\n","use_crescenta_tpu = True #Del;ete/?"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":243},"executionInfo":{"elapsed":228,"status":"error","timestamp":1621543286040,"user":{"displayName":"Morgan Ciliv","photoUrl":"","userId":"00224338928243146060"},"user_tz":420},"id":"VPMpn2UD8kc6","outputId":"0a39c714-9d8a-444b-81ea-f5b4f611453f"},"outputs":[],"source":["#@title Filenames, Paths, user input\n","\n","class Filenames:\n","  TFRECORD_EXTENSION = '.tfrecord'\n","  NIFTI_IMAGE_EXTENSION = '.nii'\n","  METAIMAGE_EXTENSION = '.mha'\n","\n","  data = 'Data'\n","  archives = 'Archives'\n","  pytorch = 'PyTorch'\n","  tensorflow = 'TensorFlow'\n","  logs = 'logs2'\n","  model = 'model'\n","  casilab = 'CASILab'\n","  casilab_labels = 'NormalDatabase2.xlsx'\n","  ixi = 'IXI'\n","  ixi_labels = 'Demographinc info_IXI.xls'\n","  mra = 'MRA'\n","  raw = 'Raw'\n","  nearest_resampling_to_128x128x50 = 'Nearest Resampling to 128x128x50'\n","  augmented1 = 'Augmented1'\n","  metaimages = 'MetaImages'\n","  niftis = 'Niftis'\n","  tfrecords = 'TFRecords'\n","\n","  def has_tfrecord_extension(filename):\n","    return len(filename) >= len(Filenames.TFRECORD_EXTENSION) and filename[-len(Filenames.TFRECORD_EXTENSION):] == Filenames.TFRECORD_EXTENSION\n","\n","  def add_potential_numeric_suffix(filepath):\n","    if not os.path.exists(filepath):\n","      return filepath\n","    number_to_suffix_with = 1\n","    while os.path.exists(filepath + \"-\" + str(number_to_suffix_with)):\n","      number_to_suffix_with += 1\n","    return filepath + \"-\" + str(number_to_suffix_with)\n","\n","  def convert_to_new_extension(filename, new_extension):\n","    try:\n","      return substring.substringByChar(filename, None, \".\")[:-1] + new_extension\n","    except:\n","      return filename + new_extension\n","\n","\n","class FilenamesTestCase(unittest.TestCase):\n","  root_dir = 'testing/'\n","\n","  def setUp(self):\n","    os.mkdir(FilenamesTestCase.root_dir)\n","\n","  def tearDown(self):\n","    os.rmdir('testing/')\n","\n","  def test_add_potential_numeric_with_no_existing_file(self):\n","    original_name = FilenamesTestCase.root_dir + 'test_file.extension'\n","    self.assertEqual(Filenames.add_potential_numeric_suffix(original_name),\n","                     original_name)\n","\n","class Paths:\n","  mri = Path('/content/drive/My Drive/AI/MRI')\n","\n","  archives = mri/Filenames.archives\n","  archives_pytorch = archives/Filenames.pytorch\n","  archives_tensorflow = archives/Filenames.tensorflow\n","  logs = archives/Filenames.logs\n","  model = archives/Filenames.model\n","\n","  data = mri/Filenames.data\n","  casilab = data/Filenames.casilab\n","  casilab_labels = casilab/Filenames.casilab_labels\n","  casilab_mra = casilab/Filenames.mra\n","  casilab_mra_raw = casilab_mra/Filenames.raw\n","  casilab_mra_raw_metaimages = casilab_mra_raw/Filenames.metaimages\n","  casilab_mra_raw_niftis = casilab_mra_raw/Filenames.niftis\n","  casilab_mra_raw_tfrecords = casilab_mra_raw/Filenames.tfrecords\n","  casilab_mra_nearest_resampling_to_128x128x50_niftis = casilab_mra/Filenames.nearest_resampling_to_128x128x50/Filenames.niftis\n","  casilab_mra_nearest_resampling_to_128x128x50_tfrecords = casilab_mra/Filenames.nearest_resampling_to_128x128x50/Filenames.tfrecords\n","  ixi = data/Filenames.ixi\n","  ixi_mra = ixi/Filenames.mra\n","  ixi_labels = ixi/Filenames.ixi_labels\n","  ixi_mra_raw = ixi_mra/Filenames.raw\n","  ixi_mra_raw_niftis = ixi_mra_raw/Filenames.niftis\n","  ixi_mra_raw_tfrecords = ixi_mra_raw/Filenames.tfrecords\n","  ixi_mra_nearest_resampling_to_128x128x50_niftis = ixi_mra/Filenames.nearest_resampling_to_128x128x50/Filenames.niftis\n","  ixi_mra_nearest_resampling_to_128x128x50_tfrecords = ixi_mra/Filenames.nearest_resampling_to_128x128x50/Filenames.tfrecords\n","\n","  def get_all_paths_in_directory(directory_path):\n","    for filename in Path.iterdir(directory_path):\n","      yield os.path.join(directory_path, filename)\n","\n","  def get_equivalent_path_with_part_replaced(path, original_part, new_part):\n","    path = Path(path)\n","    path_parts = list(path.parts)\n","    for index, part in enumerate(path_parts):\n","      if part == original_part:\n","        path_parts[index] = new_part\n","    return Path(*path_parts)\n","\n","  def run_check_on_path(path, ask=False):\n","    path = Path(path)\n","    dir = path if path.is_dir() else path.parent\n","    if not dir.exists():\n","      if not ask or UserInput.yes_or_no(\"Do you want to create the directories needed to make \" + str(dir)):\n","        try:\n","          dir.mkdir(parents=True)\n","        except FileExistsError:\n","          print(f'Directory {dir} was made already in the mean time')\n","    elif ask and len(list(dir.iterdir())) > 0:\n","      if UserInput.yes_or_no('There are files in ' + str(dir) + '. Do you want the program to exit?'):\n","        sys.exit()\n","\n","class UserInput:\n","  def yes_or_no(question):\n","    reply = str(input(question+' (y/n): ')).lower().strip()\n","    if reply[0] == 'y':\n","        return True\n","    if reply[0] == 'n':\n","        return False\n","    else:\n","        return yes_or_no(\"Uhhhh... please enter \")"]},{"cell_type":"markdown","metadata":{"id":"-UiL7KoZ-J8I"},"source":["##Storage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FomLiMcP-InI"},"outputs":[],"source":["class Storage(enum.Enum):\n","  GOOGLE_DRIVE = enum.auto()\n","  GOOGLE_CLOUD = enum.auto()\n","  USING_GCSFUSE = enum.auto()"]},{"cell_type":"markdown","metadata":{"id":"8pDFgdRS-OkK"},"source":["###Google Drive (DELETE?)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":131196,"status":"ok","timestamp":1607797245153,"user":{"displayName":"Morgan Ciliv","photoUrl":"","userId":"00224338928243146060"},"user_tz":480},"id":"cCdAgZEa-Nmo","outputId":"ccfce82c-2e78-43eb-9ae3-091dd6a7b06d"},"outputs":[],"source":["class GoogleDrive:\n","  drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AeylpYNR-Xvj"},"outputs":[],"source":["#@title If using Google Cloud\n","if use_cloud_tfrecords:\n","  class GoogleCloud:"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"eE8UrZ4Y-hp-"},"outputs":[],"source":["#@title Dataset super class\n","class Dataset(abc.ABC):\n","  @abc.abstractmethod\n","  def get_dataframe(self):\n","    ...\n","\n","  @abc.abstractmethod\n","  def get_path_to_image_data(self):\n","    ...\n","\n","  def get_list_of_file_age_pairs(self):\n","    list_of_file_age_pairs = []\n","    for row_index, series in self.get_dataframe().iterrows():\n","      list_of_file_age_pairs.append((series[\"FILE PATH\"], series[\"AGE\"]))\n","    return list_of_file_age_pairs\n","\n","  def get_new_tfrecord_file_path(self, filename):\n","    new_tfrecord_file_path = self.get_tfrecords_path() / Path(substring.substringByChar(filename, None, \".\")[:-1]).with_suffix(Filenames.TFRECORD_EXTENSION)\n","    return new_tfrecord_file_path\n","\n","    #Add more to this"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"GHN56kb7--MC"},"outputs":[],"source":["#@title CASILab\n","class CASILabDataset(Dataset):\n","  LEN_OF_ID = 3\n","  string_before_id_in_example_name = \"NormalA\"\n","  start_of_id_in_example_name = len(string_before_id_in_example_name)\n","  end_of_id_in_example_name = start_of_id_in_example_name + LEN_OF_ID - 1\n","\n","  string_before_id_in_filename = \"Normal\"\n","  string_after_id_in_filename = \"-MRA\"\n","  start_of_id_in_filename = len(string_before_id_in_filename)\n","  end_of_id_in_filename = start_of_id_in_filename + LEN_OF_ID - 1\n","\n","  example_to_not_use = 48\n","  image_shape_for_examples_1_through_95 = (448, 448, 128)\n","  image_shape_for_examples_96_through_99 = (352, 448, 176)\n","\n","  def __init__(self):\n","    self.examples_to_skip = [CASILabDataset.example_to_not_use]\n","    self.dataframe = self._get_and_initialize_dataframe()\n","    self.number_of_examples = self.dataframe.shape[0]\n","\n","  def _is_an_example_name(string):\n","    try:\n","      return substring.substringByInd(string, 0, CASILabDataset.start_of_id_in_example_name - 1) == CASILabDataset.string_before_id_in_example_name\n","    except:\n","      return False\n","\n","  def _get_casilab_id_from_example_name(example_name):\n","    return substring.substringByInd(example_name, CASILabDataset.start_of_id_in_example_name, CASILabDataset.end_of_id_in_example_name)\n","    \n","  def _is_an_example_to_not_use(self, string):\n","    return int(CASILabDataset._get_casilab_id_from_example_name(string)) in self.examples_to_skip\n","    \n","  def _is_a_row_to_drop(self, row):\n","    example_name = row['EXAMPLE NAME']\n","    age = row['AGE']\n","    return type(example_name) != str or \\\n","        not CASILabDataset._is_an_example_name(example_name) or \\\n","        self._is_an_example_to_not_use(example_name) or pd.isna(age)\n","\n","  def _get_indices_to_drop(self, dataframe):\n","    indexes_to_drop = []\n","    for i in range(dataframe.shape[0]):\n","      row = dataframe.iloc[i]\n","      if self._is_a_row_to_drop(row):\n","        indexes_to_drop.append(i)\n","    return indexes_to_drop\n","  \n","  def _get_casilab_id_from_file_path(file_path):\n","    return substring.substringByInd(file_path.name, CASILabDataset.start_of_id_in_filename, CASILabDataset.end_of_id_in_filename)\n","  \n","  def _get_casilab_id_as_int_from_file_path(file_path):\n","    return int(_get_casilab_id_from_file_path(file_path))\n","\n","  def _get_and_initialize_dataframe(self):\n","    dataframe = pd.read_excel(Paths.casilab_labels, header=None)\n","    dataframe = dataframe.rename(mapper={0: \"EXAMPLE NAME\", 6: \"AGE\"}, axis=1)\n","    dataframe = dataframe.drop(self._get_indices_to_drop(dataframe)).reset_index(drop=True)\n","    file_paths_for_dataframe = [None] * dataframe.shape[0]\n","\n","    for index, example_name in dataframe[\"EXAMPLE NAME\"].iteritems():\n","      for file_path in self.get_path_to_image_data().iterdir():\n","        if CASILabDataset._get_casilab_id_from_example_name(example_name) == CASILabDataset._get_casilab_id_from_file_path(file_path):\n","          file_paths_for_dataframe[index] = file_path\n","    dataframe.insert(loc=1, column=\"FILE PATH\", value=file_paths_for_dataframe)\n","\n","    return dataframe\n","\n","  def get_dataframe(self):\n","    return self.dataframe\n","    \n","  def get_number_of_examples(self):\n","    return self.dataframe.shape[0]\n","\n","  def get_file_path_by_index(self, example_index):\n","    return self.dataframe[\"FILE PATH\"][example_index]\n","\n","  def get_casilab_id_as_string(casilab_id):\n","    return str(casilab_id).zfill(3)\n","\n","  def get_nifti_file_path(casilab_id):\n","    return CASILabDataset.string_before_id_in_filename + CASILabDataset.get_casilab_id_as_string(casilab_id) + CASILabDataset.string_after_id_in_filename + Filenames.NIFTI_IMAGE_EXTENSION\n","\n","  def get_age(self, example_index):\n","    return self.dataframe[\"AGE\"][example_index]\n","\n","  def get_path_to_image_data(self):\n","    return Paths.casilab_mra_raw_niftis\n","\n","  def get_path_to_niftis_nearest_resampled_to_128x128x50():\n","    return Paths.casilab_mra_nearest_resampling_to_128x128x50_niftis\n","\n","  def get_nifti_file_path(self, casilab_id):\n","    return os.path.join(CASILabDataset.get_path_to_(), CASILabDataset.get_nifti_filename(casilab_id))\n","\n","  def get_tfrecords_path(self):\n","    return Paths.casilab_mra_raw_tfrecords"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"S1Ypmkkv_l6x"},"outputs":[],"source":["#@title IXI\n","class IXIDataset(Dataset): \n","  LEN_OF_ID = 3\n","  example_to_not_use = 371\n","  image_shape_from_guys_and_hammersmith_hospital = (512, 512, 100)\n","  image_shape_from_institute_of_psychiatry = (1024, 1024, 92)\n","\n","  def __init__(self):\n","    self.examples_to_skip = [IXIDataset.example_to_not_use]\n","    self.id_start_index=3\n","    self.dataframe = self._get_and_initialize_dataframe()\n","    self.number_of_examples = self.dataframe.shape[0]\n","\n","  def _get_indices_to_drop(self, dataframe):\n","    return dataframe.index[np.logical_or(np.logical_or(\n","                             dataframe['IXI_ID'] == IXIDataset.example_to_not_use,\n","                             pd.isna(dataframe['AGE'])), \n","                             pd.isna(dataframe['FILE PATH']))].tolist()\n","\n","  \n","  def _get_IXI_id(self, file_path):\n","    ixi_id_string = file_path.name[self.id_start_index:self.id_start_index + IXIDataset.LEN_OF_ID]\n","    ixi_id = int(ixi_id_string)\n","    return ixi_id\n","\n","  def _get_and_initialize_dataframe(self):\n","    dataframe = pd.read_excel(Paths.ixi_labels)\n","    number_of_ixi_ids_in_paper = dataframe['IXI_ID'].size\n","    file_paths_for_dataframe = [None] * number_of_ixi_ids_in_paper\n","    for index, element in dataframe['IXI_ID'].iteritems():\n","      for file_path in self.get_path_to_image_data().iterdir():\n","        if element == self._get_IXI_id(file_path):\n","          file_paths_for_dataframe[index] = file_path\n","    dataframe.insert(loc=1, column='FILE PATH', value=file_paths_for_dataframe)\n","    dataframe = dataframe.drop(self._get_indices_to_drop(dataframe)).reset_index(drop=True)\n","\n","    return dataframe\n","\n","  def get_dataframe(self):\n","    return self.dataframe\n","\n","  def get_file_path_by_index(self, example_index):\n","    return self.dataframe['FILE PATH'][example_index]\n","\n","  def get_age(self, example_index):\n","    return self.dataframe['AGE'][example_index]\n","\n","  def get_path_to_image_data(self):\n","    return Paths.ixi_mra_raw_niftis\n","\n","  def get_path_to_niftis_nearest_resampled_to_128x128x50():\n","    return Paths.ixi_mra_nearest_resampling_to_128x128x50_niftis\n","\n","  def get_tfrecords_path(self):\n","    return Paths.ixi_mra_raw_tfrecords"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"hwbBBKmB_oUC"},"outputs":[],"source":["#@title Serialization\n","class Serialization:\n","  def _bytes_feature(value):\n","    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","    if isinstance(value, type(tf.constant(0))):\n","      value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","  def _float_feature(value):\n","    \"\"\"Returns a float_list from a float / double.\"\"\"\n","    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","  def _int64_feature(value):\n","    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","  def serialize_example(image_array, age, affine_array=None):\n","    image_string = Serialization.serialize_numpy_array(image_array)\n","   \n","    feature = {\n","        'image': Serialization._bytes_feature(image_string),\n","        'age': Serialization._float_feature(age),\n","    }\n","\n","    if affine_array is None:\n","      affine_string = Serialization.serialize_numpy_array(affine_array)\n","      feature['affine'] = Serialization._bytes_feature(affine_string)\n","\n","    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n","    return example_proto.SerializeToString()\n","\n","  def serialize_numpy_array(array):\n","    tensor = tf.convert_to_tensor(array, dtype=tf.float32)\n","    return tf.io.serialize_tensor(tensor)\n","\n","  def serialize_nifti_image_array(image):\n","    array = np.asarray(image)\n","    return Serialization.serialize_numpy_array(array)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"NMr4um1bS59-"},"outputs":[],"source":["#@title Affines\n","class Affines:\n","  shape = (4, 4)"]},{"cell_type":"markdown","metadata":{"id":"EjL6oD23AJ7K"},"source":["##Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1KJQbLNW_56Z"},"outputs":[],"source":["class Data:\n","  def write_tfrecord(tfrecord_file_path, serialization):\n","    writer = tf.io.TFRecordWriter(str(tfrecord_file_path))\n","    writer.write(serialization)\n","    writer.close()\n","\n","  def convert_nifti_to_tfrecord(nifti_file_path, tfrecord_file_path):\n","    nifti_image = nib.load(nifti_file_path)\n","    nifti_image = Data.reshape_nifti_image_for_model(nifti_image)\n","    image_array = nifti_image.get_fdata()\n","    serialized_example = Serialization.serialize_example(image_array, age, affine_array=nifti_image.affine)\n","    Data.write_tfrecord(tfrecord_filepath, serialized_example)\n","\n","  def convert_niftis_to_tfrecords(niftis_path, tfrecords_path=None):\n","    for nifti_filename in os.listdir(niftis_path):\n","      niftis_filepath = os.path.join(niftis_path, nifti_filename)\n","      parent_filepath, _ = os.path.split(niftis_path)\n","      tfrecord_file_path = os.path.join(parent_filepath, Filenames.convert_to_new_extension(nifti_filename, Filenames.TFRECORD_EXTENSION))\n","      Data.convert_nifti_to_tfrecord(niftis_filepath, tfrecord_file_path)\n","  \n","  def create_tfrecords_dataset_from_nifti_dataset(dataset):\n","    Paths.run_check_on_path(dataset.get_tfrecords_path())\n","    for example_index in range(dataset.number_of_examples):\n","      filename = dataset.get_filename_by_index(example_index)\n","      age = dataset.get_age(example_index)\n","      if filename != None and pd.notna(age):\n","        tfrecord_filepath = dataset.get_new_tfrecord_file_path(filename)\n","        if not os.path.exists(tfrecord_filepath):\n","          nifti_file_path = dataset.get_path_to_image_data()/filename\n","          nifti_image = nib.load(nifti_file_path)\n","          image_array = nifti_image.get_fdata()\n","          serialized_example = Serialization.serialize_example(image_array, age, affine_array=nifti_image.affine)\n","          Data.write_tfrecord(tfrecord_filepath, serialized_example)\n","\n","  def create_tfrecords_datasets_from_nifti_datasets(datasets=[CASILabDataset(), IXIDataset()]):\n","    for dataset in datasets:\n","      Data.create_tfrecords_dataset_from_nifti_dataset(dataset)\n","\n","  def write_subjects_dataset_to_nifti_files(subjects_dataset):\n","    for subject in subjects_dataset:\n","        subject_image = subject.get_first_image()\n","        subject_image_array = np.squeeze(subject_image.numpy())\n","        nifti_image = nib.Nifti1Image(subject_image_array, subject_image.affine)\n","        nib.save(nifti_image, subject.output_path)\n","\n","  def get_subjects_dataset(dataset, transform=None):\n","    subjects = []\n","    source_data = type(dataset).get_path_to_niftis_nearest_resampled_to_128x128x50()\n","    new_niftis_path = Paths.get_equivalent_path_with_part_replaced(source_data, Filenames.nearest_resampling_to_128x128x50, Filenames.augmented1)\n","    Paths.run_check_on_path(new_niftis_path)\n","    for image_path in source_data.iterdir():\n","      new_nifti_file_path = Paths.get_equivalent_path_with_part_replaced(image_path, Filenames.nearest_resampling_to_128x128x50, Filenames.augmented1)\n","      if not new_nifti_file_path.exists():\n","        subject = tio.Subject(mri=tio.ScalarImage(image_path), output_path=new_nifti_file_path)\n","        subjects.append(subject)\n","    subjects_dataset = tio.SubjectsDataset(subjects, transform=transform)\n","    return subjects_dataset\n","\n","  def create_augmented_datasets(training_dataset=IXIDataset(), test_dataset=CASILabDataset()):\n","    training_transform = Compose([\n","      # ToCanonical(),\n","      # Resample(4),\n","      # CropOrPad((48, 60, 48), padding_mode='reflect'),\n","      # RandomMotion(),\n","      # HistogramStandardization({'mri': landmarks}),\n","      RandomBiasField(),\n","      # ZNormalization(masking_method=ZNormalization.mean),\n","      # RandomNoise(),\n","      # RandomFlip(axes=(0,)),\n","      # OneOf({\n","      #     RandomAffine(): 0.8,\n","      #     RandomElasticDeformation(): 0.2,\n","      # }),\n","    ])\n","\n","    # validation_transform = Compose([\n","    #   # ToCanonical(),\n","    #   Resample(4),\n","    #   CropOrPad((48, 60, 48), padding_mode='reflect'),\n","    #   HistogramStandardization({'mri': landmarks}),\n","    #   ZNormalization(masking_method=ZNormalization.mean),\n","    # ])\n","\n","    training_subjects_dataset = Data.get_subjects_dataset(training_dataset, transform=training_transform)\n","    # test_subjects = Data.get_subjects_dataset(test_dataset)\n","    Data.write_subjects_dataset_to_nifti_files(training_subjects_dataset)\n","\n","  def get_target_affine(nifti_image, target_shape):\n","    shape = nifti_image.get_fdata().shape\n","    zooms = np.diag(nifti_image.affine)[:3] * np.divide(shape, target_shape)\n","    return rescale_affine(nifti_image.affine, shape, zooms, new_shape=target_shape)\n","  \n","  def reshape_nifti_image_for_model(nifti_image):\n","    target_affine = Data.get_target_affine(nifti_image, AgePredictor.image_shape)\n","    return nilearn.image.resample_img(nifti_image, target_affine=target_affine, target_shape=AgePredictor.image_shape, interpolation='nearest')\n","\n","  def create_reshaped_nifti_from_nifti(nifti_file_path, reshaped_nifti_file_path):\n","    nifti_image = nib.load(nifti_file_path)\n","    reshaped_nifti_image = Data.reshape_nifti_image_for_model(nifti_image)\n","    Paths.run_check_on_path(nifti_file_path)\n","    nib.save(nifti_image, reshaped_nifti_file_path)\n","\n","  def create_reshaped_niftis_from_niftis(niftis_path):\n","    Paths.run_check_on_path(niftis_path) \n","    for nifti_file_path in Paths.get_all_paths_in_directory(niftis_path):\n","      Data.create_reshaped_nifti_from_nifti(nifti_file_path, Paths.get_equivalent_path_with_part_replaced(nifti_file_path, Filenames.raw, Filenames.nearest_resampling_to_128x128x50))\n","\n","  def create_reshaped_niftis_from_niftis_for_datasets(datasets=[IXIDataset()]):\n","    for dataset in datasets:\n","      Data.create_reshaped_niftis_from_niftis(dataset.get_path_to_image_data())\n","\n","  def convert_metaimage_to_nifti1image(metaimage_file_path, nifti1image_file_path):\n","    image = sitk.ReadImage(metaimage_file_path)\n","    sitk.WriteImage(image, nifti1image_file_path)\n","\n","  def convert_metaimages_to_nifti1images(metaimage_path, nifti1image_path):\n","    if metaimage_path[-1] != '/':\n","      metaimage_path += '/'\n","    if nifti1image_path[-1] != '/':\n","      nifti1image_path += '/'\n","    for filename in os.listdir(metaimage_path):\n","      filename_without_extension = substring.substringByChar(filename, None, '.')[:-1]\n","      metaimage_file_path = metaimage_path + filename\n","      nifti1image_file_path = nifti1image_path + filename_without_extension + Filenames.NIFTI_IMAGE_EXTENSION\n","      if not os.path.exists(nifti1image_file_path):\n","        Data.convert_metaimage_to_nifti1image(metaimage_file_path, nifti1image_file_path)\n","\n","  def move_directory_from_google_drive_to_google_cloud(directory_path):\n","    directory_shell_path = shlex.quote(directory_path)\n","    !gsutil cp -m file://{directory_shell_path}* {GoogleCloud.bucket_contents_uri}\n","\n","  def get_dataset_size(dataset):\n","    return len(os.listdir(dataset.get_tfrecords_path()))"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"elapsed":149,"status":"error","timestamp":1621546095092,"user":{"displayName":"Morgan Ciliv","photoUrl":"","userId":"00224338928243146060"},"user_tz":420},"id":"CaTOudZiAP3C","outputId":"5ebcaa1e-8a59-4c55-aaf7-e2191500dcd1"},"outputs":[],"source":["#@title Plotting\n","class Plotting:\n","  casilab_dataset = CASILabDataset()\n","  def plot_nifti_image_using_niwidgets(nifti_image):\n","    image = niwidgets.NiftiWidget(nifti_image)\n","    image.nifti_plotter()\n","\n","  def plot_nifti_image_using_nilearn(nifti_image):\n","    plotting.plot_img(nifti_image)\n","    # nilearn.plotting.plot_anat(nifti_image, cut_coords=None, display_mode='ortho')\n","\n","  def plot_nifti_image(nifti_image):\n","    Plotting.plot_nifti_image_using_nilearn(nifti_image)\n","\n","  def plot_nifti_file(nifti_file_path):\n","    nifti_image = nib.load(nifti_file_path)\n","    Plotting.plot_nifti_image(nifti_image)\n","\n","  def plot_casilab_nifti_file(casilab_id):\n","    nifti_file_path = casilab_dataset.get_nifti_file_path(casilab_id)\n","    Plotting.plot_nifti_file(nifti_file_path)\n","\n","  def plot_nifti_image_reshaped(nifti_image):\n","    nifti_image_with_target_shape = Data.reshape_nifti_image_for_model(nifti_image)\n","    Plotting.plot_nifti_image(nifti_image_with_target_shape)\n","\n","  def plot_nifti_file_reshaped(nifti_file_path):\n","    nifti_image = nib.load(nifti_file_path)\n","    Plotting.plot_nifti_image_reshaped(nifti_image)\n","\n","  def plot_casilab_nifti_file_reshaped(casilab_id):\n","    nifti_file_path = casilab_dataset.get_nifti_file_path(casilab_id)\n","    Plotting.plot_nifti_file_reshaped(nifti_file_path)\n","\n","  def plot_original_and_reshaped_version_of_casilab_nifti_file(casilab_id):\n","    print(\"Original version of first casilab nifti file\")\n","    Plotting.plot_casilab_nifti_file(casilab_id)\n","    print(\"Reshaped version of first casilab nifti file\")\n","    Plotting.plot_casilab_nifti_file_reshaped(casilab_id)\n","\n","  def plot_mri_scan(image_array, affine):\n","    try:\n","      nifti_image = nib.Nifti1Image(image_array, affine)\n","    except:\n","      nifti_image = nib.Nifti2Image(image_array, affine)\n","    plot_nifti_image(nifti_image)\n","\n","  def tensorboard():\n","    logdir = shlex.quote(str(Paths.logs))\n","    %tensorboard --logdir {logdir}"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"x642k0arBGMm"},"outputs":[],"source":["#@title Visualization functions from torchIO_tutorial.ipynb\n","# https://colab.research.google.com/github/fepegar/torchio-notebooks/blob/main/notebooks/TorchIO_tutorial.ipynb#scrollTo=QS_PG3sMsH4w\n","def show_nifti(image_path_or_image, colormap='gray'):\n","    try:\n","        from niwidgets import NiftiWidget\n","        with warnings.catch_warnings():\n","            warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","            widget = NiftiWidget(image_path_or_image)\n","            widget.nifti_plotter(colormap=colormap)\n","    except Exception:\n","        if isinstance(image_path_or_image, nib.AnalyzeImage):\n","            nii = image_path_or_image\n","        else:\n","            image_path = image_path_or_image\n","            nii = nib.load(str(image_path))\n","        k = int(nii.shape[-1] / 2)\n","        plt.imshow(nii.dataobj[..., k], cmap=colormap)\n","\n","def show_subject(subject, image_name, label_name=None):\n","    if label_name is not None:\n","        subject = copy.deepcopy(subject)\n","        affine = subject[label_name].affine\n","        label_image = subject[label_name].as_sitk()\n","        label_image = sitk.Cast(label_image, sitk.sitkUInt8)\n","        border = sitk.BinaryContour(label_image)\n","        border_array, _ = tio.utils.sitk_to_nib(border)\n","        border_tensor = torch.from_numpy(border_array)[0]\n","        image_tensor = subject[image_name].data[0]\n","        image_tensor[border_tensor > 0.5] = image_tensor.max()\n","    with tempfile.NamedTemporaryFile(suffix='.nii') as f:\n","        subject[image_name].save(f.name)\n","        show_nifti(f.name)\n","\n","def plot_histogram(axis, tensor, num_positions=100, label=None, alpha=0.05, color=None):\n","    values = tensor.numpy().ravel()\n","    kernel = stats.gaussian_kde(values)\n","    positions = np.linspace(values.min(), values.max(), num=num_positions)\n","    histogram = kernel(positions)\n","    kwargs = dict(linewidth=1, color='black' if color is None else color, alpha=alpha)\n","    if label is not None:\n","        kwargs['label'] = label\n","    axis.plot(positions, histogram, **kwargs)\n","\n","# Visualization functions from https://colab.research.google.com/github/fepegar/torchio-notebooks/blob/main/notebooks/Data_preprocessing_and_augmentation_using_TorchIO_a_tutorial.ipynb#scrollTo=IA2LRIRc62Pr&uniqifier=2\n","def get_bounds(self):\n","    \"\"\"Get image bounds in mm.\n","\n","    Returns:\n","        np.ndarray: [description]\n","    \"\"\"\n","    first_index = 3 * (-0.5,)\n","    last_index = np.array(self.spatial_shape) - 0.5\n","    first_point = nib.affines.apply_affine(self.affine, first_index)\n","    last_point = nib.affines.apply_affine(self.affine, last_index)\n","    array = np.array((first_point, last_point))\n","    bounds_x, bounds_y, bounds_z = array.T.tolist()\n","    return bounds_x, bounds_y, bounds_z\n","\n","def to_pil(image):\n","    from PIL import Image\n","    from IPython.display import display\n","    data = image.numpy().squeeze().T\n","    data = data.astype(np.uint8)\n","    image = Image.fromarray(data)\n","    w, h = image.size\n","    display(image)\n","    print()  # in case multiple images are being displayed\n","\n","def stretch(img):\n","    p1, p99 = np.percentile(img, (1, 99))\n","    from skimage import exposure\n","    img_rescale = exposure.rescale_intensity(img, in_range=(p1, p99))\n","    return img_rescale\n","\n","def show_fpg(\n","        subject,\n","        to_ras=False,\n","        stretch_slices=True,\n","        indices=None,\n","        intensity_name='t1',\n","        parcellation=True,\n","        ):\n","    subject = tio.ToCanonical()(subject) if to_ras else subject\n","    def flip(x):\n","        return np.rot90(x)\n","    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n","    if indices is None:\n","        half_shape = torch.Tensor(subject.spatial_shape) // 2\n","        i, j, k = half_shape.long()\n","        i -= 5  # use a better slice\n","    else:\n","        i, j, k = indices\n","    bounds_x, bounds_y, bounds_z = get_bounds(subject.t1)  ###\n","\n","    orientation = ''.join(subject.t1.orientation)\n","    if orientation != 'RAS':\n","        import warnings\n","        warnings.warn(f'Image orientation should be RAS+, not {orientation}+')\n","    \n","    kwargs = dict(cmap='gray', interpolation='none')\n","    data = subject[intensity_name].data\n","    slices = data[0, i], data[0, :, j], data[0, ..., k]\n","    if stretch_slices:\n","        slices = [stretch(s.numpy()) for s in slices]\n","    sag, cor, axi = slices\n","    \n","    axes[0, 0].imshow(flip(sag), extent=bounds_y + bounds_z, **kwargs)\n","    axes[0, 1].imshow(flip(cor), extent=bounds_x + bounds_z, **kwargs)\n","    axes[0, 2].imshow(flip(axi), extent=bounds_x + bounds_y, **kwargs)\n","\n","    kwargs = dict(interpolation='none')\n","    data = subject.seg.data\n","    slices = data[0, i], data[0, :, j], data[0, ..., k]\n","    if parcellation:\n","        sag, cor, axi = [color_table.colorize(s.long()) if s.max() > 1 else s for s in slices]\n","    else:\n","        sag, cor, axi = slices\n","    axes[1, 0].imshow(flip(sag), extent=bounds_y + bounds_z, **kwargs)\n","    axes[1, 1].imshow(flip(cor), extent=bounds_x + bounds_z, **kwargs)\n","    axes[1, 2].imshow(flip(axi), extent=bounds_x + bounds_y, **kwargs)\n","    \n","    plt.tight_layout()\n","\n","\n","class ColorTable:\n","    def __init__(self, colors_path):\n","        self.df = self.read_color_table(colors_path)\n","\n","    @staticmethod\n","    def read_color_table(colors_path):\n","        df = pd.read_csv(\n","            colors_path,\n","            sep=' ',\n","            header=None,\n","            names=['Label', 'Name', 'R', 'G', 'B', 'A'],\n","            index_col='Label',\n","        )\n","        return df\n","\n","    def get_color(self, label: int):\n","        \"\"\"\n","        There must be nicer ways of doing this\n","        \"\"\"\n","        try:\n","            rgb = (\n","                self.df.loc[label].R,\n","                self.df.loc[label].G,\n","                self.df.loc[label].B,\n","            )\n","        except KeyError:\n","            rgb = 0, 0, 0\n","        return rgb\n","\n","    def colorize(self, label_map: np.ndarray) -> np.ndarray:\n","        rgb = np.stack(3 * [label_map], axis=-1)\n","        for label in np.unique(label_map):\n","            mask = label_map == label\n","            color = self.get_color(label)\n","            rgb[mask] = color\n","        return rgb\n","\n","color_table = ColorTable('colormap.txt')"]},{"cell_type":"markdown","metadata":{"id":"wQP6uWY6AgGA"},"source":["##Hardware"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JIev7Ay8AeS_"},"outputs":[],"source":["class Hardware:\n","  def get_strategy():\n","    strategy = tf.distribute.get_strategy()\n","    try:\n","      if use_crescenta_tpu:\n","        resolver = tf.distribute.cluster_resolver.TPUClusterResolver\n","      else:\n","        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","      tf.config.experimental_connect_to_cluster(resolver)\n","      # This is the TPU initialization code that has to be at the beginning.\n","      tf.tpu.experimental.initialize_tpu_system(resolver)\n","      strategy = tf.distribute.TPUStrategy(resolver)\n","      print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n","    except:\n","      pass\n","    return strategy"]},{"cell_type":"markdown","metadata":{"id":"aKz1aljUApyx"},"source":["##Dataset Info Callback"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J5TzNYzSAlXB"},"outputs":[],"source":["class DatasetInfoCallback(keras.callbacks.Callback):\n","  i = 0\n","  def __init__(self, training_set_size, validation_set_size, test_set_size):\n","    self.training_set_size = training_set_size\n","    self.validation_set_size = validation_set_size\n","    self.test_set_size = test_set_size\n","    \n","  def on_train_begin(self, logs=None):\n","    tf.summary.text('Training set size', str(self.training_set_size), step=0)\n","    tf.summary.text('Validation set size', str(self.validation_set_size), step=0)\n","    tf.summary.text('Test set size', str(self.test_set_size), step=0)"]},{"cell_type":"markdown","metadata":{"id":"Xy8JAdBTNWxG"},"source":["##Action"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8abNL6xVNUav"},"outputs":[],"source":["class Action(enum.Enum):\n","    TRAIN = 'Training'\n","    VALIDATE = 'Validation'\n","    TEST = 'Test'"]},{"cell_type":"markdown","metadata":{"id":"2jFY_oL3bcIk"},"source":["##Alarm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cAdv25q_bXHg"},"outputs":[],"source":["class Alarm:\n","  def bell():\n","    sys.stdout.write('\\r\\a')\n","    sys.stdout.flush()"]},{"cell_type":"markdown","metadata":{"id":"LkWlCCd6Fa8h"},"source":["##Age Predictor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uV8oE_76E9YD"},"outputs":[],"source":["class AgePredictor(abc.ABC):\n","  batch_size = 16\n","  num_epochs = 64\n","  image_shape = (128, 128, 50)\n","\n","  def __init__(self):\n","    self.start_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","    self.logdir = self.get_logdir()/self.start_datetime\n","\n","  @abc.abstractmethod\n","  def get_logdir(self):\n","    ...\n","\n","  preprocessing_transform = Compose([\n","    ToCanonical(),\n","    Resample(1, image_interpolation='bspline'),\n","    CropOrPad((128, 128, 50), padding_mode='reflect'),\n","    #   HistogramStandardization({'mri': landmarks}),\n","    #   ZNormalization(masking_method=ZNormalization.mean),\n","  ])\n","\n","  augmentation_transform = Compose([\n","    # RandomMotion(),\n","    RandomBiasField(),\n","    RandomNoise(),\n","    RandomFlip(axes=(0,)),\n","    # OneOf({\n","    #     RandomAffine(): 0.8,\n","    #     RandomElasticDeformation(): 0.2,\n","    # }),\n","  ])"]},{"cell_type":"markdown","metadata":{"id":"VSCcyfr2rKd-"},"source":["###Age Predictor Using Torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wk3S0RdFrIhR"},"outputs":[],"source":["class AgePredictorUsingTorch(AgePredictor):\n","  def get_logdir(self):\n","    return Paths.archives_pytorch\n","\n","  def get_model_and_optimizer_and_loss(self):\n","    model = nn.Sequential(\n","        nn.Conv3d(1, 8, 3),\n","        nn.Dropout(0.2),\n","        nn.ReLU(),\n","        nn.MaxPool3d(2),\n","\n","        nn.Conv3d(8, 8, 3),\n","        nn.Dropout(0.2),\n","        nn.ReLU(),\n","        nn.MaxPool3d(2),\n","\n","        nn.Conv3d(8, 16, 3),\n","        nn.Dropout(0.2),\n","        nn.ReLU(),\n","        nn.MaxPool3d(2),\n","\n","        nn.Flatten(),\n","\n","        nn.Linear(12544, 128),\n","        nn.Dropout(0.3),\n","        nn.ReLU(),\n","\n","        nn.Linear(128, 1),\n","        nn.Dropout(0.3),\n","        nn.ReLU(),\n","    ).to(self.device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=10e-5)\n","    loss = nn.L1Loss()\n","    return model, optimizer, loss\n","  \n","  def get_data_loader(self, dataset, is_distributed=True, shuffle=False, sampler=None):\n","    if is_distributed:\n","      batch_size=self.batch_size\n","      num_workers=self.num_workers\n","      drop_last=True\n","    else:\n","      batch_size=AgePredictor.batch_size\n","      num_workers=multiprocessing.cpu_count()\n","      drop_last=False\n","\n","    return torch.utils.data.DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","        sampler=sampler,\n","        num_workers=num_workers,\n","        drop_last=drop_last\n","    )\n","\n","  def get_distributed_sampler(self, dataset, shuffle=False):\n","    return torch.utils.data.distributed.DistributedSampler(\n","             dataset,\n","             num_replicas=xm.xrt_world_size(),\n","             rank=xm.get_ordinal(),\n","             shuffle=True)\n","\n","  def get_subjects_dataset(self, file_age_pairs, augment=False):\n","    subjects = []\n","    for image_path, age in file_age_pairs:\n","      subject = tio.Subject(mri=tio.ScalarImage(path=image_path), age=age)\n","      subjects.append(subject)\n","    transform = AgePredictor.preprocessing_transform\n","    if augment:\n","      transform = Compose([transform, AgePredictor.augmentation_transform])\n","    subjects_dataset = tio.SubjectsDataset(subjects, transform=transform)\n","    return subjects_dataset\n","      \n","  def __init__(self, device, flags=None, is_distributed=True, process_index=1):\n","    super().__init__()\n","    self.device = device\n","    self.process_index = process_index\n","    if flags != None:\n","      try:\n","        self.batch_size = flags['batch_size']\n","      except:\n","        pass\n","      try:\n","        self.num_epochs = flags['num_epochs']\n","      except:\n","        pass\n","      try:\n","        self.num_workers = flags['num_workers']\n","      except:\n","        if is_distributed:\n","          raise Exception(\"Num workers must be provided to run distributedly\")\n","\n","    fitting_file_age_pairs = IXIDataset().get_list_of_file_age_pairs()\n","    training_split_ratio = 0.9\n","    num_fitting_subjects = len(fitting_file_age_pairs)\n","    num_training_subjects = int(training_split_ratio * num_fitting_subjects)\n","\n","    training_file_age_pairs = fitting_file_age_pairs[:num_training_subjects]\n","    validation_file_age_pairs = fitting_file_age_pairs[num_training_subjects:]\n","    test_file_age_pairs = CASILabDataset().get_list_of_file_age_pairs()\n","\n","    # if not xm.is_master_ordinal():\n","    #   xm.rendezvous('all_workers_received_data')\n","\n","    training_set_subjects_dataset = self.get_subjects_dataset(training_file_age_pairs, augment=True)\n","    validation_set_subjects_dataset = self.get_subjects_dataset(validation_file_age_pairs)\n","    test_set_subjects_dataset = self.get_subjects_dataset(test_file_age_pairs)\n","\n","    # if xm.is_master_ordinal():\n","    #   xm.rendezvous('all_workers_received_data')\n","    # if self.process_index == 0:\n","    #   time.sleep(2)\n","\n","    training_sampler, validation_sampler, test_sampler = None, None, None\n","    if is_distributed:\n","      training_sampler = self.get_distributed_sampler(training_set_subjects_dataset, shuffle=True)\n","      validation_sampler = self.get_distributed_sampler(validation_set_subjects_dataset)\n","      test_sampler = self.get_distributed_sampler(test_set_subjects_dataset)\n","\n","    self.training_loader = self.get_data_loader(training_set_subjects_dataset, is_distributed, shuffle=not is_distributed, sampler=training_sampler)\n","    self.validation_loader = self.get_data_loader(validation_set_subjects_dataset, is_distributed, sampler=validation_sampler)\n","    self.test_loader = self.get_data_loader(test_set_subjects_dataset, is_distributed, sampler=test_sampler)\n","\n","    self.model, self.optimizer, self.loss = self.get_model_and_optimizer_and_loss()\n","\n","  def forward(self, inputs):\n","    with warnings.catch_warnings():\n","        warnings.filterwarnings(\"ignore\", category=UserWarning)\n","        prediction = self.model(inputs)\n","    return prediction\n","\n","  def prepare_batch(self, batch):\n","    inputs = batch['mri'][DATA].to(self.device)\n","    targets = batch['age'].to(self.device)\n","    return inputs, targets\n","  \n","  def run_epoch(self, action, loader, is_distributed=True, epoch_idx=None):\n","    epoch_start = time.time()\n","    is_training = action == Action.TRAIN\n","    self.model.train(is_training)\n","    if is_distributed:\n","      loader = pl.ParallelLoader(self.training_loader, [self.device]).per_device_loader(self.device)\n","    epoch_losses = torch.zeros(len(loader))\n","    for batch_idx, batch in enumerate(loader):\n","        inputs, targets = self.prepare_batch(batch)\n","        self.optimizer.zero_grad()\n","        with torch.set_grad_enabled(is_training):\n","            predicted_age = self.forward(inputs)\n","            targets = targets.view_as(predicted_age)\n","            batch_loss = self.loss(predicted_age, targets)\n","            epoch_losses[batch_idx] = batch_loss\n","            if is_training:\n","                batch_loss.backward()\n","                if self.device.type != 'cuda' and self.device.type != 'cpu':\n","                  xm.optimizer_step(self.optimizer, barrier=not is_distributed)\n","                else:\n","                  self.optimizer.step()\n","    elapsed_epoch_time = time.time() - epoch_start\n","    print(f'Epoch {epoch_idx}: {action.value} mean absolute age difference: {torch.mean(epoch_losses).item():0.3f} in {elapsed_epoch_time} seconds')\n","\n","  def train(self, is_distributed=True, weights_stem='whole images'):\n","    train_start = time.time()\n","    self.run_epoch(Action.VALIDATE, self.validation_loader, epoch_idx=0)\n","    for epoch_idx in range(1, AgePredictor.num_epochs + 1):\n","        print('Starting epoch', epoch_idx)\n","        self.run_epoch(Action.TRAIN, self.training_loader, epoch_idx=epoch_idx)\n","        self.run_epoch(Action.VALIDATE, self.validation_loader, epoch_idx=epoch_idx)\n","        file_path = f'{self.logdir/weights_stem}_epoch_{epoch_idx}.pth'\n","        file_path = Filenames.add_potential_numeric_suffix(file_path)\n","        Paths.run_check_on_path(file_path)\n","        save_function = xm.save if is_distributed else torch.save\n","        save_function(self.model.state_dict(), file_path)\n","    elapsed_train_time = time.time() - train_start\n","    print(\"Epoch Process\", self.process_index, \"finished training. Train time was:\", elapsed_train_time, \" seconds\") \n","\n","  def test(self):\n","    # GEt modle from weight directory\n","    eval_start = time.time()\n","    self.run_epoch(Action.TEST, self.test_loader)\n","    elapsed_eval_time = time.time() - eval_start\n","    print(\"Process\", self.process_index, \"finished evaluation. Evaluation time was:\", elapsed_eval_time, \" seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GdMUfNejKcvD"},"outputs":[],"source":["# At global scope.\n","SERIAL_EXEC = xmp.MpSerialExecutor()\n","\n","# import torch_xla.debug.metrics as met\n","def map_fn(index, flags):\n","  torch.manual_seed(flags['seed'])\n","  device = xm.xla_device()\n","  # if not xm.is_master_ordinal():\n","  #   xm.rendezvous('download_only_once')\n","\n","  age_predictor_using_torch = AgePredictorUsingTorch(device, flags, process_index=index) #is this in the right place?\n","\n","  # if xm.is_master_ordinal():\n","  #   xm.rendezvous('download_only_once')\n","\n","  age_predictor_using_torch.train()\n","  age_predictor_using_torch.test()\n","\n","def run(distributed=True):\n","  flags = {}\n","  flags['batch_size'] = AgePredictor.batch_size\n","  flags['num_epochs'] = AgePredictor.num_epochs\n","  flags['num_workers'] = 8 if os.environ.get('TPU_NAME', None) else 1\n","  flags['seed'] = 0\n","  if distributed:\n","    xmp.spawn(map_fn, args=(flags,), nprocs=8, start_method='fork')\n","  else:\n","    try:\n","      device = xm.xla_device()\n","    except:\n","      device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n","    print(\"Not using multiprocessing, using device: \", str(device))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145378,"status":"ok","timestamp":1607797259442,"user":{"displayName":"Morgan Ciliv","photoUrl":"","userId":"00224338928243146060"},"user_tz":480},"id":"IC1_ws5gHW-2","outputId":"f08f9ec4-cd99-45aa-b3fa-5a63d786a380"},"outputs":[],"source":["batch_loss = torch.tensor(3)\n","batch_loss2 = torch.tensor(4)\n","epoch_losses = []\n","epoch_losses.append(batch_loss)\n","epoch_losses.append(batch_loss2)\n","epoch_losses = np.array(epoch_losses)\n","\n","print(epoch_losses.mean())"]},{"cell_type":"markdown","metadata":{"id":"D4pePPoeA0Wv"},"source":["###Age Predictor Using Tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZw6isFpjBNP"},"outputs":[],"source":["class AgePredictorUsingTensorflow(AgePredictor):\n","  # batch_size = 16 * tpu_strategy.num_replicas_in_sync()\n","\n","  def get_logdir(self):\n","    return Paths.archives_tensorflow\n","\n","  def _get_tfrecord_filepaths(retrieve_from, dataset):\n","    if retrieve_from in {Storage.GOOGLE_CLOUD, Storage.USING_GCSFUSE}:\n","      tfrecord_filepaths = !gsutil ls {bucket_contents_uri}\n","    if retrieve_from == Storage.USING_GCSFUSE:\n","      !echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n","      !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n","      !apt -qq update\n","      !apt -qq install gcsfuse\n","      tfrecords_path = '/content/crescenta_bucket/'\n","      !gcsfuse {bucket_contents_uri} {tfrecords_path}\n","      tfrecord_filenames = [get_filename_from_path(tfrecord_filename) for tfrecord_filename in tfrecord_filepaths]\n","    if retrieve_from == Storage.GOOGLE_DRIVE:\n","      tfrecords_path = dataset.get_tfrecords_path()\n","    if retrieve_from in {Storage.GOOGLE_DRIVE, Storage.USING_GCSFUSE}:\n","      tfrecord_filepaths = tfrecords_path.iterdir()\n","      tfrecord_filepaths = [str(tfrecord_filepath) for tfrecord_filepath in tfrecord_filepaths]\n","    return tfrecord_filepaths\n","\n","  def __init__(self, training_dataset=IXIDataset(), test_dataset=CASILabDataset(), retrieve_from=Storage.GOOGLE_DRIVE):\n","    self.file_writer = tf.summary.create_file_writer(self.logdir + \"/metrics\")\n","    self.file_writer.set_as_default()\n","    self.tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=self.logdir, histogram_freq=1)\n","    self.modeldir = os.path.join(Paths.model, start_datetime)\n","\n","    self.input_shape = AgePredictor.image_shape + (1,)\n","\n","    tfrecord_filepaths_for_fitting = AgePredictorUsingTensorflow._get_tfrecord_filepaths(retrieve_from, training_dataset)\n","    number_of_training_examples = int(len(tfrecord_filepaths_for_fitting) * .9)\n","    self.tfrecord_filepaths_for_training = tfrecord_filepaths_for_fitting[:number_of_training_examples]\n","    self.tfrecord_filepaths_for_validation = tfrecord_filepaths_for_fitting[number_of_training_examples:]\n","    self.tfrecord_filepaths_for_testing = AgePredictorUsingTensorflow._get_tfrecord_filepaths(retrieve_from, test_dataset)\n","    self.dataset_info_callback = DatasetInfoCallback(len(self.tfrecord_filepaths_for_training), len(self.tfrecord_filepaths_for_validation), len(self.tfrecord_filepaths_for_testing))\n","    self.input_fn_callable = lambda: self.input_fn(tfrecord_filepaths=self.tfrecord_filepaths_for_training)\n","    self._initialize_and_compile_keras_model()\n","\n","  # def get_normalization_layer(dataset):\n","  #   # Create a Normalization layer for our feature.\n","  #   normalizer = Normalization()\n","\n","  #   # Prepare a Dataset that only yields our feature.\n","  #   feature_ds = dataset.map(lambda x, y: x)\n","\n","  #   # Learn the statistics of the data.\n","  #   normalizer.adapt(feature_ds)\n","\n","  #   return normalizer\n","\n","  def _initialize_and_compile_keras_model(self):\n","    # normalization_layer = AgePredictorUsingTensorflow.get_normalization_layer(self.input_fn(self.tfrecord_filepaths_for_training))\n","\n","    with Hardware.get_strategy().scope():\n","      # inputs = Input(shape=AgePredictorUsingTensorflow.input_shape)\n","      # normalized_inputs = normalization_layer(inputs)\n","      \n","      sequential_part = Sequential([\n","        Conv3D(8, 3, input_shape=self.input_shape),\n","        Dropout(0.2),\n","        Activation('relu'),\n","        MaxPooling3D(),\n","\n","        Conv3D(8, 3),\n","        Dropout(0.2),\n","        Activation('relu'),\n","        MaxPooling3D(),\n","\n","        Conv3D(16, 3),\n","        Dropout(0.2),\n","        Activation('relu'),\n","        MaxPooling3D(),\n","\n","        Flatten(),\n","\n","        Dense(128),\n","        Dropout(0.3),\n","        Activation('relu'),\n","\n","        Dense(1),\n","        Dropout(0.3),\n","        Activation('relu'),\n","      ])\n","\n","      # outputs = sequential_part(normalized_inputs)\n","\n","      self._keras_model = sequential_part # Model(inputs, outputs)\n","      self._keras_model.summary()\n","      self._keras_model.compile(loss='mean_absolute_error', optimizer=Adam(lr=0.0001))\n","\n","\n","  def _tranform_example(self, dictionary, augment=False):\n","    image_array = tf.make_ndarray(dictionary['image'])\n","    image_array = np.moveaxis(image_array, image_array.ndim - 1, 0) \n","    image = tio.ScalarImage(tensor=image_array, affine=dictionary['affine'].numpy())\n","    preprocessing_transform = Compose([\n","      ToCanonical(),\n","      Resample(1),\n","      CropOrPad((128, 128, 50), padding_mode='reflect'),\n","    #   HistogramStandardization({'mri': landmarks}),\n","      ZNormalization(masking_method=ZNormalization.mean),\n","    ])\n","\n","    transformed_image = preprocessing_transform(image)\n","    if augment:\n","      augmentation_transform = Compose([\n","        # RandomMotion(),\n","        RandomBiasField(),\n","        RandomNoise(),\n","        RandomFlip(axes=(0,)),\n","        # How about random flipping in other directions?\n","        # OneOf({\n","        #     RandomAffine(): 0.8,\n","        #     RandomElasticDeformation(): 0.2,\n","        # }),\n","      ])\n","      transformed_image = augmentation_transform(transformed_image)\n","    image_array = np.moveaxis(transformed_image.numpy(), 0, image_array.ndim - 1)\n","    image_tensor = tf.convert_to_tensor(image_array)\n","    return (image_tensor, dictionary['age'])\n","\n","  def _make_example(self, dictionary):\n","    return (dictionary['image'], dictionary['age'])\n","\n","  def _make_dictionary(self, features_dict):\n","    example_dictionary = {}\n","    example_dictionary['image'] = features_dict['image']    \n","    example_dictionary['image'] = tf.io.parse_tensor(example_dictionary['image'], out_type=tf.float32)\n","    example_dictionary['image'] = tf.reshape(example_dictionary['image'], list(AgePredictorUsingTensorflow.input_shape))\n","\n","    try:\n","      example_dictionary['affine'] = features_dict['affine']\n","      example_dictionary['affine'] = tf.io.parse_tensor(example_dictionary['affine'], out_type=tf.float32)\n","      example_dictionary['affine'] = tf.reshape(example_dictionary['affine'], list(Affines.shape))\n","    except:\n","      pass\n","\n","    example_dictionary['age'] = features_dict['age']\n","\n","    return example_dictionary\n","\n","  def _parse(features_proto, get_affine=True): \n","    feature_description = {\n","      'image': tf.io.FixedLenFeature([], tf.string),\n","      'age': tf.io.FixedLenFeature([], tf.float32),\n","    }\n","    if get_affine:\n","      feature_description['affine'] = tf.io.FixedLenFeature([], tf.string)\n","    return tf.io.parse_single_example(features_proto, feature_description)\n","\n","  def input_fn(self, tfrecord_filepaths, shuffle=False, augment=False):\n","    ipdb.set_trace()\n","    AUTO = tf.data.experimental.AUTOTUNE\n","    serialized_dataset = tf.data.TFRecordDataset(tfrecord_filepaths, num_parallel_reads=AUTO)    \n","    parsed_dataset = serialized_dataset.map(AgePredictorUsingTensorflow._parse, num_parallel_calls=AUTO)\n","    dictionaries_dataset = parsed_dataset.map(self._make_dictionary, num_parallel_calls=AUTO)\n","    examples_dataset = dictionaries_dataset.map(self._make_example, num_parallel_calls=AUTO)\n","    # numpy_dataset = tfds.examples_dataset\n","    # transform_example_callable = lambda dictionary: self._tranform_example(dictionary, augment=augment)\n","    # examples_dataset = examples_dataset.map(transform_example_callable, num_parallel_calls=AUTO)\n","    if shuffle:\n","      examples_dataset = examples_dataset.shuffle(len(examples_dataset))\n","    batched_dataset = examples_dataset.batch(AgePredictorUsingTensorflow.batch_size)\n","    batched_dataset = batched_dataset.prefetch(buffer_size=AUTO)\n","    return batched_dataset\n","\n","  def train_keras_model(self):\n","    self._keras_model.fit(x=self.input_fn(self.tfrecord_filepaths_for_training, shuffle=True, augment=True), epochs=self.num_epochs, callbacks=[self.tensorboard_callback, self.dataset_info_callback], validation_data=self.input_fn(self.tfrecord_filepaths_for_validation))\n","    self._keras_model.save(Filenames.add_potential_numeric_suffix(self.modeldir))\n","\n","  def get_latest_model_dir():\n","    return os.path.join(Paths.model, os.listdir(Paths.model)[-1])\n","\n","  def load_most_recent_runs_weights_into_keras_model(self):\n","    latest_model_dir = AgePredictorUsingTensorflow.get_latest_model_dir()\n","    self._keras_model = load_model(latest_model_dir)\n","\n","  def evaluate_keras_model(self):\n","    self.load_most_recent_runs_weights_into_keras_model()\n","    self._keras_model.evaluate(x=self.input_fn(self.tfrecord_filepaths_for_testing), batch_size=AgePredictorUsingTensorflow.batch_size, callbacks=[self.tensorboard_callback])\n","\n","  def predict_with_keras_model(self, tfrecord_filepaths):\n","    self._keras_model.predict(x=self.input_fn(tfrecord_filepaths), batch_size=1, callbacks=[self.tensorboard_callbacks])\n","    \n","  def _initialize_estimator(self):\n","    model_dir = tempfile.mkdtemp()\n","    self.estimator = tf.keras.estimator.model_to_estimator(keras_model=self._keras_model, model_dir=model_dir)\n","\n","  ''' For estimators, train, evaluate, and predict functions, probably need to break up the dataset per each'''\n","  def train_estimator(self):\n","    self.estimator.train(input_fn=self.input_fn_callable, steps=AgePredictorUsingTensorflow.num_epochs)\n","  \n","  def evaluate_estimator(self):\n","    eval_result = self.estimator.evaluate(input_fn=self.input_fn_callable)\n","    print('Eval result: {}'.format(eval_result))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-L8itlO1BXrW"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"8tkUMfrFBS6d"},"source":["#Main"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hFRfAqjBRzD","outputId":"b7ac3c69-183a-4f34-fde9-5996343dfe73"},"outputs":[],"source":["if __name__ == '__main__':\n","  try:\n","    use_torch = True\n","    if use_torch:\n","      # age_predictor_using_torch = AgePredictorUsingTorch()\n","      # age_predictor_using_torch.train()\n","      # age_predictor_using_torch.test()\n","      run()\n","    else:\n","      unittest.main(argv=['first-arg-is-ignored'], exit=False)\n","      Plotting.tensorboard()\n","      # age_predictor = AgePredictor()\n","      # age_predictor.train_keras_model()\n","      # age_predictor.evaluate_keras_model()\n","  except Exception as e:\n","    Alarm.bell()\n","    raise e\n","  "]},{"cell_type":"markdown","metadata":{"id":"bCF4l4Z5Bdk6"},"source":["#Test Ground"]},{"cell_type":"markdown","metadata":{"id":"1la6d9-u7aX4"},"source":["# References"]},{"cell_type":"markdown","metadata":{"id":"QQJG0vz9WWYh"},"source":["Code references:\n","[TPUs in Colab](https://colab.research.google.com/notebooks/tpu.ipynb#scrollTo=LtAVr-4CP1rp)\n","\n","Data references:\n","http://brain-development.org/ixi-dataset/,\n","http://insight-journal.org/midas/community/view/21\n"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"MRI.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
